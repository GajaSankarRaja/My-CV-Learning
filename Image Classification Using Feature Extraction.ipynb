{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c76dafc0-97f9-4274-b4dc-a9de94a6c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from img2vec_keras import Img2Vec\n",
    "from img2vec_pytorch import Img2Vec\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "338ed882-90bf-4f16-a549-15cf325c74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='D:/dataset2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05d0391e-f8fc-446b-a0ff-2084d444c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1123\n"
     ]
    }
   ],
   "source": [
    "category = ['cloudy', 'sunrise', 'shine', 'rain']\n",
    "three, two = 0, 0\n",
    "for ind in category:\n",
    "    category_path = os.path.join(dataset, ind)\n",
    "    for file in os.listdir(category_path):\n",
    "        path = os.path.join(category_path, file)\n",
    "        img = cv.imread(path)\n",
    "        if img is not None:\n",
    "            shape = img.shape\n",
    "            if len(shape) == 2:\n",
    "                two += 1\n",
    "            elif len(shape) == 3:\n",
    "                three += 1\n",
    "        else:\n",
    "            print(f\"Failed to load image: {path}\")\n",
    "print(two)\n",
    "print(three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ec5257b-9a60-4159-902f-0c69386ad446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "data,labels=[],[]\n",
    "img2vec = Img2Vec()\n",
    "category = ['cloudy', 'rain','shine','sunrise']\n",
    "for ind,ele in enumerate(category):\n",
    "    category_path = os.path.join(dataset, ele)\n",
    "    for file in os.listdir(category_path):\n",
    "        path = os.path.join(category_path, file)\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        if img is not None:\n",
    "            d=img2vec.get_vec(img)\n",
    "            #print(d)\n",
    "            data.append(d)\n",
    "            labels.append(ind)\n",
    "        else:\n",
    "            print(f\"Failed to load image: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb9efb25-23c6-4b55-bb0d-e8e676277383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(data,labels,test_size=0.3,random_state=1,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed15b3cc-7819-45b2-b800-64c37d266a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifer=RandomForestClassifier(n_estimators=50,max_depth=5,oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b80a4963-6451-483b-9098-70902496ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer.fit(xtrain,ytrain)\n",
    "ypred=classifer.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54c79e69-df1b-489a-80c1-e30d4acf5b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9703264094955489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "print(accuracy_score(ytest,ypred))\n",
    "#print(precision_score(ytest,ypred))\n",
    "#print(recall_score(ytest,ypred))\n",
    "#print(f1_score(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b747d1cf-ff56-4f40-9392-48abd0121be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "model=SVC(kernel='poly')\n",
    "classifier_svm=OneVsOneClassifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6ae22ca-6377-4d9c-9d68-2602e86aabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svm.fit(xtrain,ytrain)\n",
    "ypred1=classifier_svm.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96c08721-d0fc-47cf-9a2e-e3aee0f82916",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xtrain,ytrain)\n",
    "ypred=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b64af82-bf7e-40a8-93a5-37556f61294d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9940652818991098"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db572088-8a37-4be2-8341-b33e9c83b60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9881305637982196"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0be79bef-faa9-4fc0-93cf-8218fac22d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898\n",
      "225\n",
      "tf.Tensor(b'cloudy', shape=(), dtype=string)\n",
      "tf.Tensor(b'shine', shape=(), dtype=string)\n",
      "tf.Tensor(b'cloudy', shape=(), dtype=string)\n",
      "tf.Tensor(b'cloudy', shape=(), dtype=string)\n",
      "tf.Tensor(b'cloudy', shape=(), dtype=string)\n",
      "tf.Tensor(b'cloudy', shape=(), dtype=string)\n",
      "tf.Tensor(b'sunrise', shape=(), dtype=string)\n",
      "tf.Tensor(b'cloudy', shape=(), dtype=string)\n",
      "tf.Tensor(b'shine', shape=(), dtype=string)\n",
      "tf.Tensor(b'shine', shape=(), dtype=string)\n",
      "tf.Tensor(b'cloudy', shape=(), dtype=string)\n",
      "tf.Tensor(b'sunrise', shape=(), dtype=string)\n",
      "<dtype: 'float32'>\n",
      "tf.Tensor(b'rain', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "data_url='D:/dataset2/*/*'\n",
    "data_url\n",
    "data=tf.data.Dataset.list_files(data_url,shuffle=True)\n",
    "size=int(len(data)*0.8)\n",
    "train_ds=data.take(size)\n",
    "test_ds=data.skip(size)\n",
    "print(len(train_ds))\n",
    "print(len(test_ds))\n",
    "for i in train_ds.take(2).as_numpy_iterator():\n",
    "    print(tf.strings.split(i,'\\\\')[-2])\n",
    "def get_label(filepath):\n",
    "    return tf.strings.split(filepath,'\\\\')[-2]\n",
    "def preprocess_img(filepath):\n",
    "    img=tf.io.read_file(filepath)\n",
    "    label=get_label(filepath)\n",
    "    img=tf.io.decode_jpeg(img,channels=3)\n",
    "    img = tf.image.resize(img, [160, 160])         \n",
    "    img = img / 255.0 \n",
    "    return img,label\n",
    "for i in train_ds.take(10).map(get_label,num_parallel_calls=tf.data.AUTOTUNE):\n",
    "    print(i)\n",
    "for img,label in train_ds.map(preprocess_img,num_parallel_calls=tf.data.AUTOTUNE).take(1):\n",
    "    print(img.dtype)\n",
    "    print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44a978ab-09a9-4c8a-be48-a9ec23676dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cloudy', 'rain', 'shine', 'sunrise']\n",
      "Epoch 1/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 464ms/step - accuracy: 0.3457 - loss: 30.4179 - val_accuracy: 0.6711 - val_loss: 6.4841\n",
      "Epoch 2/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 452ms/step - accuracy: 0.6718 - loss: 4.2824 - val_accuracy: 0.5111 - val_loss: 5.1715\n",
      "Epoch 3/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 464ms/step - accuracy: 0.6357 - loss: 3.2311 - val_accuracy: 0.6267 - val_loss: 5.8511\n",
      "Epoch 4/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 483ms/step - accuracy: 0.5894 - loss: 6.4596 - val_accuracy: 0.8222 - val_loss: 0.7384\n",
      "Epoch 5/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 423ms/step - accuracy: 0.7689 - loss: 1.0132 - val_accuracy: 0.5956 - val_loss: 1.8225\n",
      "Epoch 6/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 420ms/step - accuracy: 0.6724 - loss: 1.3835 - val_accuracy: 0.6889 - val_loss: 1.3576\n",
      "Epoch 7/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 443ms/step - accuracy: 0.7879 - loss: 0.7564 - val_accuracy: 0.7822 - val_loss: 0.5674\n",
      "Epoch 8/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 413ms/step - accuracy: 0.7729 - loss: 0.5779 - val_accuracy: 0.7956 - val_loss: 0.4666\n",
      "Epoch 9/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 440ms/step - accuracy: 0.7161 - loss: 1.3267 - val_accuracy: 0.8578 - val_loss: 0.4526\n",
      "Epoch 10/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 407ms/step - accuracy: 0.8197 - loss: 0.6180 - val_accuracy: 0.7822 - val_loss: 0.5647\n",
      "Epoch 11/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 420ms/step - accuracy: 0.8304 - loss: 0.4883 - val_accuracy: 0.7644 - val_loss: 1.3616\n",
      "Epoch 12/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 422ms/step - accuracy: 0.7177 - loss: 1.7388 - val_accuracy: 0.7911 - val_loss: 0.5051\n",
      "Epoch 13/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 476ms/step - accuracy: 0.7673 - loss: 0.6757 - val_accuracy: 0.8311 - val_loss: 0.4617\n",
      "Epoch 14/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 422ms/step - accuracy: 0.7870 - loss: 0.5410 - val_accuracy: 0.8622 - val_loss: 0.4093\n",
      "Epoch 15/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 419ms/step - accuracy: 0.8285 - loss: 0.5367 - val_accuracy: 0.8356 - val_loss: 0.4093\n",
      "Epoch 16/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 423ms/step - accuracy: 0.8039 - loss: 0.5208 - val_accuracy: 0.8444 - val_loss: 0.5323\n",
      "Epoch 17/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 488ms/step - accuracy: 0.8320 - loss: 0.4621 - val_accuracy: 0.7689 - val_loss: 0.4964\n",
      "Epoch 18/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 503ms/step - accuracy: 0.8079 - loss: 0.5144 - val_accuracy: 0.8133 - val_loss: 0.4502\n",
      "Epoch 19/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 514ms/step - accuracy: 0.7595 - loss: 0.6863 - val_accuracy: 0.7733 - val_loss: 0.6053\n",
      "Epoch 20/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 424ms/step - accuracy: 0.8174 - loss: 0.4965 - val_accuracy: 0.7911 - val_loss: 0.4935\n",
      "Epoch 21/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 465ms/step - accuracy: 0.8192 - loss: 0.4889 - val_accuracy: 0.8578 - val_loss: 0.3416\n",
      "Epoch 22/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 447ms/step - accuracy: 0.8556 - loss: 0.3414 - val_accuracy: 0.7689 - val_loss: 0.6072\n",
      "Epoch 23/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 439ms/step - accuracy: 0.7550 - loss: 0.8778 - val_accuracy: 0.8622 - val_loss: 0.5787\n",
      "Epoch 24/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 419ms/step - accuracy: 0.8447 - loss: 0.4279 - val_accuracy: 0.7911 - val_loss: 0.4572\n",
      "Epoch 25/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 429ms/step - accuracy: 0.8608 - loss: 0.3940 - val_accuracy: 0.8844 - val_loss: 0.2920\n",
      "Epoch 26/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 415ms/step - accuracy: 0.8815 - loss: 0.3079 - val_accuracy: 0.8844 - val_loss: 0.3237\n",
      "Epoch 27/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 413ms/step - accuracy: 0.8840 - loss: 0.3131 - val_accuracy: 0.8622 - val_loss: 0.3886\n",
      "Epoch 28/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 418ms/step - accuracy: 0.9069 - loss: 0.2687 - val_accuracy: 0.9067 - val_loss: 0.2919\n",
      "Epoch 29/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 431ms/step - accuracy: 0.8905 - loss: 0.2915 - val_accuracy: 0.8800 - val_loss: 0.2317\n",
      "Epoch 30/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 420ms/step - accuracy: 0.8619 - loss: 0.3543 - val_accuracy: 0.7822 - val_loss: 0.4989\n",
      "Epoch 31/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 498ms/step - accuracy: 0.8024 - loss: 0.5333 - val_accuracy: 0.9067 - val_loss: 0.2600\n",
      "Epoch 32/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 462ms/step - accuracy: 0.8888 - loss: 0.3005 - val_accuracy: 0.8222 - val_loss: 0.4475\n",
      "Epoch 33/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 415ms/step - accuracy: 0.8918 - loss: 0.2892 - val_accuracy: 0.8800 - val_loss: 0.3488\n",
      "Epoch 34/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 416ms/step - accuracy: 0.8537 - loss: 0.3375 - val_accuracy: 0.8889 - val_loss: 0.3209\n",
      "Epoch 35/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 420ms/step - accuracy: 0.8843 - loss: 0.3249 - val_accuracy: 0.8800 - val_loss: 0.2886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25740a68bc0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract class names from your dataset\n",
    "class_names = sorted(set([str(tf.strings.split(i, '\\\\')[-2].numpy(), 'utf-8')for i in data.as_numpy_iterator()]))\n",
    "\n",
    "print(class_names) \n",
    "label_to_index = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(class_names),\n",
    "        values=tf.constant(list(range(len(class_names))), dtype=tf.int64),\n",
    "    ),\n",
    "    default_value=-1  \n",
    ")\n",
    "def get_label(filepath):\n",
    "    class_name = tf.strings.split(filepath, '\\\\')[-2]\n",
    "    return label_to_index.lookup(class_name)\n",
    "\n",
    "def preprocess_img(filepath):\n",
    "    label = get_label(filepath)\n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [160, 160])\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "train_ds = train_ds.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # accepts integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7492cfa4-3c01-406d-bab9-2141a678acfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9206 - loss: 0.2387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27034735679626465, 0.897777795791626]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63fda7-ec71-4206-9042-36a31711b3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
